{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from downloadDiaryOfSessions.main import download\n",
    "from rabbitmqSender.main import RabbitSender\n",
    "from diaryParser.main import  parse_diary\n",
    "\n",
    "from json import loads as json_loads, dumps as json_dumps\n",
    "from os.path import isdir\n",
    "from bs4 import BeautifulSoup\n",
    "from os import listdir, makedirs, mkdir\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "\n",
    "legislatures = [11, 12, 13, 14]\n",
    "roman_legislatures = ['xi', 'xii', 'xiii', 'xiv']\n",
    "max_errors = 50\n",
    "data_folder = './.data/'\n",
    "dscd_path = f'{data_folder}diary_session_congress_deputies_pdfs'\n",
    "dss_path = f'{data_folder}diary_session_senate_pdfs'\n",
    "texts_folder_path = f'{data_folder}texts'\n",
    "speeches_folder_path = f'{data_folder}speeches'\n",
    "speeches_to_index_folder_path = f'{data_folder}speeches_to_index'\n",
    "open_data_senators_xml = 'https://www.senado.es/web/ficopendataservlet?tipoFich=10#'\n",
    "open_data_groups_xml = 'https://www.senado.es/web/ficopendataservlet?tipoFich=4&legis=13#'\n",
    "senators_xml_path = f'{data_folder}opendata_senators.xml'\n",
    "groups_xml_path = f'{data_folder}opendata_group.xml'\n",
    "people_senate_csv_path = f'{data_folder}people_senate.csv'\n",
    "people_congress_csv_path = f'{data_folder}people_congress.csv'\n",
    "people_ministers_csv_path = f'{data_folder}people_ministers.csv'\n",
    "people_csv_path = f'{data_folder}people.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.- Download diary of sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def diary_session_congress_deputies_url(legislature, plenary):\n",
    "    return f\"https://www.congreso.es/public_oficiales/L{legislature}/CONG/DS/PL/DSCD-{legislature}-PL-{plenary}.PDF\"\n",
    "\n",
    "\n",
    "def diary_session_senate_url(legislature, plenary):\n",
    "    return f\"https://www.senado.es/legis{legislature}/publicaciones/pdf/senado/ds/DS_C_{legislature}_{plenary}.PDF\"\n",
    "\n",
    "\n",
    "def download_diary_session(local_path, prefix, diary_session_url):\n",
    "    if not isdir(local_path):\n",
    "        makedirs(local_path)\n",
    "\n",
    "    for current_legislature in legislatures:\n",
    "        current_plenary = 1\n",
    "        consecutive_errors = 0\n",
    "        while consecutive_errors < max_errors:\n",
    "            url = diary_session_url(current_legislature, current_plenary)\n",
    "            file = f\"{prefix}-{current_legislature}-{current_plenary:03d}\"\n",
    "            if download(url, local_path, file):\n",
    "                consecutive_errors = 0\n",
    "            else:\n",
    "                consecutive_errors += 1\n",
    "\n",
    "            current_plenary += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1.- Diary of session congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "download_diary_session(dscd_path, 'dscd', diary_session_congress_deputies_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2.- Diary of session senate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "download_diary_session(dss_path, 'dss', diary_session_senate_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.- Convert pdf pages to images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`docker-compose -f docker-compose-pdf-to-img.yml -p tfg-pdf-to-img up -d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sender = RabbitSender('localhost', 5672, 'myuser', 'mypassword', 'pdf-to-img')\n",
    "\n",
    "for file in listdir(dscd_path):\n",
    "    sender.send(f'{dscd_path}/{file}'[len(data_folder):])\n",
    "\n",
    "for file in listdir(dss_path):\n",
    "    sender.send(f'{dss_path}/{file}'[len(data_folder):])\n",
    "\n",
    "sender.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[RabbitMQ queues management](http://localhost:15672/#/queues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.- Optical character recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`docker-compose -f docker-compose-img-to-txt.yml -p tfg-img-to-txt up -d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sender = RabbitSender('localhost', 5672, 'myuser', 'mypassword', 'img-to-txt')\n",
    "\n",
    "for file in listdir(f'{data_folder}images'):\n",
    "    sender.send(file)\n",
    "\n",
    "sender.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.- Get people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.1.- Deputies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_deputies(legislature):\n",
    "    url_deputies = \"https://www.congreso.es/busqueda-de-diputados?p_p_id=diputadomodule&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_resource_id=searchDiputados&p_p_cacheability=cacheLevelPage\"\n",
    "\n",
    "    payload={'_diputadomodule_idLegislatura': legislature,\n",
    "             '_diputadomodule_genero': '0',\n",
    "             '_diputadomodule_grupo': 'all',\n",
    "             '_diputadomodule_tipo': '2',\n",
    "             '_diputadomodule_nombre': '',\n",
    "             '_diputadomodule_apellidos': '',\n",
    "             '_diputadomodule_formacion': 'all',\n",
    "             '_diputadomodule_filtroProvincias': '[]',\n",
    "             '_diputadomodule_nombreCircunscripcion': ''}\n",
    "\n",
    "    response = requests.request(\"POST\", url_deputies, data=payload)\n",
    "    return response.text\n",
    "\n",
    "df_deputies = None\n",
    "for current_legislature in legislatures:\n",
    "    json = get_deputies(11)\n",
    "    data = json_loads(json)\n",
    "    df = json_normalize(data['data'])\n",
    "    df_deputies = df if df_deputies is None else pd.concat([df_deputies, df])\n",
    "\n",
    "df_deputies = df_deputies.sort_values('apellidos').drop_duplicates(subset=['apellidosNombre', 'genero', 'grupo', 'formacion'])\n",
    "df_deputies.to_csv(people_congress_csv_path, index=False)\n",
    "df_deputies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.2.- Senators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "senators_response = requests.get(open_data_senators_xml)\n",
    "with open(senators_xml_path, 'w', encoding='utf-8') as senators_file:\n",
    "    senators_file.write(senators_response.text)\n",
    "\n",
    "groups_response = requests.get(open_data_groups_xml)\n",
    "groups_data = BeautifulSoup(groups_response.text, 'xml')\n",
    "data_headers = groups_data.findAll('datosCabecera')\n",
    "\n",
    "groups = []\n",
    "for header in data_headers:\n",
    "    groups.append({\n",
    "        'code': header.find('codigo').text,\n",
    "        'fullname': header.find('nombre').text,\n",
    "        'acronym': header.find('siglas').text\n",
    "    })\n",
    "\n",
    "with open(groups_xml_path, 'w', encoding='utf-8') as groups_file:\n",
    "    groups_file.write(groups_response.text)\n",
    "\n",
    "df_senators = pd.read_xml(senators_xml_path)\n",
    "df_senators = df_senators[df_senators['legislatura'].isin(legislatures)]\n",
    "\n",
    "df_groups = pd.DataFrame(groups)\n",
    "\n",
    "df_senate = pd.merge(df_senators, df_groups, how='left', left_on=['grupoSiglas'], right_on=['code'])\n",
    "df_senate.to_csv(people_senate_csv_path, index=False)\n",
    "df_senate"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error at parse dss-12-098.txt\n",
      "error at parse dss-12-133.txt\n",
      "error at parse dss-12-386.txt\n",
      "error at parse dss-12-394.txt\n",
      "error at parse dss-14-221.txt\n",
      "error at parse dss-14-334.txt\n",
      "error at parse dss-14-382.txt\n"
     ]
    }
   ],
   "source": [
    "## 4.3.- Ministers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_government_page(roman):\n",
    "    url1 = f'https://www.lamoncloa.gob.es/gobierno/gobiernosporlegislaturas/Paginas/{roman}-legislatura.aspx'\n",
    "    url2 = f'https://www.lamoncloa.gob.es/gobierno/gobiernosporlegislaturas/Paginas/{roman}_legislatura.aspx'\n",
    "    url3 = f'https://www.lamoncloa.gob.es/gobierno/gobiernosporlegislaturas/Paginas/{roman}legislatura.aspx'\n",
    "    url4 = f'https://www.lamoncloa.gob.es/gobierno/gobiernosporlegislaturas/Paginas/{roman}legislatura.aspx'\n",
    "    url5 = f'https://www.lamoncloa.gob.es/gobierno/gobiernosporlegislaturas/Paginas/{roman.upper()}legislatura.aspx'\n",
    "    url6 = f'https://www.lamoncloa.gob.es/gobierno/gobiernosporlegislaturas/Paginas/{roman.upper()}Legislatura.aspx'\n",
    "    url7 = f'https://www.lamoncloa.gob.es/gobierno/gobiernosporlegislaturas/Paginas/{roman.upper()} Legislatura.aspx'\n",
    "    urls = [url1, url2, url3, url4, url5, url6, url7]\n",
    "\n",
    "    for url in urls:\n",
    "        ministers_response = requests.get(url)\n",
    "        page = BeautifulSoup(ministers_response.text, 'html.parser')\n",
    "        lis = page.select(\"#MainContent ul li\")\n",
    "        for li in lis:\n",
    "            yield li.text\n",
    "\n",
    "        ps = page.select(\"#MainContent blockquote p\")\n",
    "        for p in ps:\n",
    "            if p.text.startswith('•'):\n",
    "                yield p.text[1:]\n",
    "\n",
    "        if len(lis) > 0 or len(ps) > 0:\n",
    "            break\n",
    "\n",
    "data_ministers = []\n",
    "for rl in roman_legislatures:\n",
    "    for minister in get_government_page(rl):\n",
    "        parts = minister.rsplit(': ', 1)\n",
    "        if len(parts) < 2:\n",
    "            parts = minister.rsplit(', ', 1)\n",
    "\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "\n",
    "        charge = parts[0]\n",
    "        name = parts[1].strip()\n",
    "        l = legislatures[roman_legislatures.index(rl)]\n",
    "        minister_data = { 'charge': charge, 'fullname': name, 'acronym': '', 'roman_legislature': rl, 'legislature': l }\n",
    "        data_ministers.append(minister_data)\n",
    "\n",
    "df_ministers = pd.DataFrame(data_ministers).drop_duplicates()\n",
    "df_ministers['unidecode_fullname'] = df_ministers['fullname'].str.replace(\"-\", \" \").str.upper().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_ministers.to_csv(people_ministers_csv_path, index=False)\n",
    "df_ministers"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>unidecode_name</th>\n      <th>surname</th>\n      <th>unidecode_surname</th>\n      <th>group</th>\n      <th>acronym</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JOSEBA ANDONI</td>\n      <td>JOSEBA ANDONI</td>\n      <td>AGIRRETXEA URRESTI</td>\n      <td>AGIRRETXEA URRESTI</td>\n      <td>GRUPO PARLAMENTARIO VASCO (EAJ-PNV)</td>\n      <td>EAJ-PNV</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NAYUA MIRIAM</td>\n      <td>NAYUA MIRIAM</td>\n      <td>ALBA GOVELI</td>\n      <td>ALBA GOVELI</td>\n      <td>GRUPO PARLAMENTARIO PODEMOS-EN COMÚ PODEM-EN M...</td>\n      <td>PODEMOS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JOAQUÍN</td>\n      <td>JOAQUIN</td>\n      <td>ALBALADEJO MARTÍNEZ</td>\n      <td>ALBALADEJO MARTINEZ</td>\n      <td>GRUPO PARLAMENTARIO POPULAR EN EL CONGRESO</td>\n      <td>PP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MIRIAM</td>\n      <td>MIRIAM</td>\n      <td>ALCONCHEL GONZAGA</td>\n      <td>ALCONCHEL GONZAGA</td>\n      <td>GRUPO PARLAMENTARIO SOCIALISTA</td>\n      <td>PSOE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ÍÑIGO JESÚS</td>\n      <td>INIGO JESUS</td>\n      <td>ALLI MARTÍNEZ</td>\n      <td>ALLI MARTINEZ</td>\n      <td>GRUPO PARLAMENTARIO MIXTO</td>\n      <td>UPN-PP</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>923</th>\n      <td>MIGUEL ÁNGEL</td>\n      <td>MIGUEL ANGEL</td>\n      <td>VISO DIÉGUEZ</td>\n      <td>VISO DIEGUEZ</td>\n      <td>GRUPO PARLAMENTARIO POPULAR EN EL SENADO</td>\n      <td>GPP</td>\n    </tr>\n    <tr>\n      <th>924</th>\n      <td>FRANCISCO JAVIER</td>\n      <td>FRANCISCO JAVIER</td>\n      <td>YANGUAS FERNÁNDEZ</td>\n      <td>YANGUAS FERNANDEZ</td>\n      <td>GRUPO PARLAMENTARIO MIXTO</td>\n      <td>GPMX</td>\n    </tr>\n    <tr>\n      <th>925</th>\n      <td>CARLOS</td>\n      <td>CARLOS</td>\n      <td>YÉCORA ROCA</td>\n      <td>YECORA ROCA</td>\n      <td>GRUPO PARLAMENTARIO POPULAR EN EL SENADO</td>\n      <td>GPP</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>PÍO RÓMULO</td>\n      <td>PIO ROMULO</td>\n      <td>ZELAYA CASTRO</td>\n      <td>ZELAYA CASTRO</td>\n      <td>GRUPO PARLAMENTARIO SOCIALISTA</td>\n      <td>GPS</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>ALEJANDRO JOSÉ</td>\n      <td>ALEJANDRO JOSE</td>\n      <td>ZUBELDIA SANTOYO</td>\n      <td>ZUBELDIA SANTOYO</td>\n      <td>GRUPO PARLAMENTARIO SOCIALISTA</td>\n      <td>GPS</td>\n    </tr>\n  </tbody>\n</table>\n<p>928 rows × 6 columns</p>\n</div>",
      "text/plain": "                 name    unidecode_name              surname  \\\n0       JOSEBA ANDONI     JOSEBA ANDONI   AGIRRETXEA URRESTI   \n1        NAYUA MIRIAM      NAYUA MIRIAM          ALBA GOVELI   \n2             JOAQUÍN           JOAQUIN  ALBALADEJO MARTÍNEZ   \n3              MIRIAM            MIRIAM    ALCONCHEL GONZAGA   \n4         ÍÑIGO JESÚS       INIGO JESUS        ALLI MARTÍNEZ   \n..                ...               ...                  ...   \n923      MIGUEL ÁNGEL      MIGUEL ANGEL         VISO DIÉGUEZ   \n924  FRANCISCO JAVIER  FRANCISCO JAVIER    YANGUAS FERNÁNDEZ   \n925            CARLOS            CARLOS          YÉCORA ROCA   \n926        PÍO RÓMULO        PIO ROMULO        ZELAYA CASTRO   \n927    ALEJANDRO JOSÉ    ALEJANDRO JOSE     ZUBELDIA SANTOYO   \n\n       unidecode_surname                                              group  \\\n0     AGIRRETXEA URRESTI                GRUPO PARLAMENTARIO VASCO (EAJ-PNV)   \n1            ALBA GOVELI  GRUPO PARLAMENTARIO PODEMOS-EN COMÚ PODEM-EN M...   \n2    ALBALADEJO MARTINEZ         GRUPO PARLAMENTARIO POPULAR EN EL CONGRESO   \n3      ALCONCHEL GONZAGA                     GRUPO PARLAMENTARIO SOCIALISTA   \n4          ALLI MARTINEZ                          GRUPO PARLAMENTARIO MIXTO   \n..                   ...                                                ...   \n923         VISO DIEGUEZ           GRUPO PARLAMENTARIO POPULAR EN EL SENADO   \n924    YANGUAS FERNANDEZ                          GRUPO PARLAMENTARIO MIXTO   \n925          YECORA ROCA           GRUPO PARLAMENTARIO POPULAR EN EL SENADO   \n926        ZELAYA CASTRO                     GRUPO PARLAMENTARIO SOCIALISTA   \n927     ZUBELDIA SANTOYO                     GRUPO PARLAMENTARIO SOCIALISTA   \n\n     acronym  \n0    EAJ-PNV  \n1    PODEMOS  \n2         PP  \n3       PSOE  \n4     UPN-PP  \n..       ...  \n923      GPP  \n924     GPMX  \n925      GPP  \n926      GPS  \n927      GPS  \n\n[928 rows x 6 columns]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 4.4.- Merge and normalize people datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#https://www.lamoncloa.gob.es/gobierno/gobiernosporlegislaturas/Paginas/xiv_legislatura.aspx\n",
    "\n",
    "df_senators = pd.read_csv(people_senate_csv_path)\n",
    "df_senators['unidecode_name'] = df_senators['nombre'].str.replace(\"-\", \" \").str.upper().str.normalize(\n",
    "    'NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_senators['unidecode_surname'] = df_senators['apellidos'].str.replace(\"-\", \" \").str.upper().str.normalize(\n",
    "    'NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "df_deputies = pd.read_csv(people_congress_csv_path)\n",
    "df_deputies['unidecode_name'] = df_deputies['nombre'].str.replace(\"-\", \" \").str.upper().str.normalize(\n",
    "    'NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_deputies['unidecode_surname'] = df_deputies['apellidos'].str.replace(\"-\", \" \").str.upper().str.normalize(\n",
    "    'NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "df_deputies['name'] = df_deputies['nombre'].str.upper()\n",
    "df_deputies['surname'] = df_deputies['apellidos'].str.upper()\n",
    "df_deputies['group'] = df_deputies['grupo'].str.upper()\n",
    "df_deputies['acronym'] = df_deputies['formacion'].str.upper()\n",
    "\n",
    "df_deputies['unidecode_fullname'] = df_deputies[['unidecode_name', 'unidecode_surname']].agg(' '.join, axis=1)\n",
    "\n",
    "df_senators['name'] = df_senators['nombre'].str.upper()\n",
    "df_senators['surname'] = df_senators['apellidos'].str.upper()\n",
    "df_senators['group'] = df_senators['fullname'].str.upper()\n",
    "df_senators['acronym'] = df_senators['acronym'].str.upper()\n",
    "\n",
    "df_senators['unidecode_fullname'] = df_senators[['unidecode_name', 'unidecode_surname']].agg(' '.join, axis=1)\n",
    "\n",
    "df_people = pd.concat([\n",
    "    df_deputies[['name', 'unidecode_name', 'surname', 'unidecode_surname', 'unidecode_fullname', 'group', 'acronym']],\n",
    "    df_senators[['name', 'unidecode_name', 'surname', 'unidecode_surname', 'unidecode_fullname', 'group', 'acronym']]],\n",
    "    ignore_index=True)\n",
    "\n",
    "df_people.to_csv(people_csv_path, index=False)\n",
    "\n",
    "df_people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ministers = pd.read_csv(people_ministers_csv_path)\n",
    "for ind in df_ministers.index:\n",
    "    fullname = df_ministers['unidecode_fullname'][ind]\n",
    "    found = df_people.loc[df_people['unidecode_fullname'] == fullname]\n",
    "    if found.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    acronym = found.iloc[0]['acronym']\n",
    "    df_ministers.at[ind, 'acronym'] = acronym\n",
    "\n",
    "df_ministers.fillna('', inplace=True)\n",
    "df_ministers.to_csv(people_ministers_csv_path, index=False)\n",
    "df_ministers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5.- Obtenir discursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not isdir(speeches_folder_path):\n",
    "    mkdir(speeches_folder_path)\n",
    "\n",
    "text_paths = listdir(texts_folder_path)\n",
    "for text_path in text_paths:\n",
    "    path = f'{texts_folder_path}/{text_path}'\n",
    "    parts = text_path[:-4].split('-')\n",
    "\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        try:\n",
    "            speeches = parse_diary(text, parts[0], int(parts[1]), int(parts[2]))\n",
    "            for speech in speeches:\n",
    "                speech_path = f'{speeches_folder_path}/{text_path[:-4]}-{speech[\"order\"]:03d}.json'\n",
    "                json_speech = json_dumps(speech, indent=4, ensure_ascii=False)\n",
    "                with open(speech_path, 'w', encoding='utf-8') as speech_file:\n",
    "                    speech_file.write(json_speech)\n",
    "        except IndexError:\n",
    "            print('error at parse', text_path)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.1.- Incloure informació personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not isdir(speeches_to_index_folder_path):\n",
    "    makedirs(speeches_to_index_folder_path)\n",
    "\n",
    "df_people = pd.read_csv(people_csv_path)\n",
    "df_ministers = pd.read_csv(people_ministers_csv_path)\n",
    "\n",
    "def find_personal_info(speech_info):\n",
    "    if 'surname' not in speech_info or speech_info['surname'] is None:\n",
    "        return None\n",
    "\n",
    "    surname = speech_info['surname'].strip().upper()\n",
    "    surname = unidecode(surname).replace(\"-\", \" \")\n",
    "\n",
    "    if surname == 'PRESIDENTE' or surname == 'PRESIDENTA':\n",
    "        if 'presidency' not in speech_info or speech_info['presidency'] is None:\n",
    "            return None\n",
    "\n",
    "        fullname = speech_info['presidency'].strip().upper()\n",
    "        fullname = unidecode(fullname)\n",
    "        found_president = df_people.loc[df_people['unidecode_name'] + ' ' + df_people['unidecode_surname'] == fullname]\n",
    "        if found_president.shape[0] == 0:\n",
    "            return None\n",
    "        return found_president.iloc[0].to_dict()\n",
    "\n",
    "    surname_with_explanatory = [\n",
    "        'CANDIDATO A LA PRESIDENCIA DEL GOBIERNO'\n",
    "        'SECRETARIO',\n",
    "        'SECRETARIA',\n",
    "        'VICEPRESIDENTA',\n",
    "        'VICEPRESIDENTE',\n",
    "        'PRESIDENTE DEL GOBIERNO EN FUNCIONES',\n",
    "        'PRESIDENTA DEL GOBIERNO EN FUNCIONES',\n",
    "        'DEFENSORA DEL PUEBLO',\n",
    "        'DEFENSOR DEL PUEBLO',\n",
    "        'MINISTRO DEL INTERIOR EN FUNCIONES',\n",
    "        'MINISTRA DEL INTERIOR EN FUNCIONES'\n",
    "    ]\n",
    "    if surname in surname_with_explanatory and 'explanatory' in speech_info:\n",
    "        surname = speech_info['explanatory'].strip().upper()\n",
    "        surname = unidecode(surname).replace(\"-\", \" \")\n",
    "\n",
    "    found = df_people.loc[df_people['unidecode_surname'] == surname]\n",
    "    if found.shape[0] == 0:\n",
    "        surname = re.sub(r\"^DE LOS \", \"\", surname)\n",
    "        surname = re.sub(r\"^DE LAS \", \"\", surname)\n",
    "        surname = re.sub(r\"^DE LA \", \"\", surname)\n",
    "        surname = re.sub(r\"^DEL \", \"\", surname)\n",
    "        surname = re.sub(r\"^DE \", \"\", surname)\n",
    "        found = df_people.loc[df_people['unidecode_surname'] == surname]\n",
    "        if found.shape[0] == 0:\n",
    "            return None\n",
    "    return found.iloc[0].to_dict()\n",
    "\n",
    "\n",
    "def parse_speech(speech_file_name):\n",
    "    raw_path = f'{speeches_folder_path}/{speech_file_name}'\n",
    "    out_path = f'{speeches_to_index_folder_path}/{speech_file_name}'\n",
    "\n",
    "    with open(raw_path, 'r', encoding='utf-8') as raw_speech_file:\n",
    "        speech = json_loads(raw_speech_file.read())\n",
    "        personal_info = find_personal_info(speech)\n",
    "        if personal_info is None:\n",
    "            print(raw_path, speech['surname'] if 'surname' in speech else 'NULL', 'Author not found')\n",
    "            return\n",
    "        speech['name'] = personal_info['name']\n",
    "        speech['surname'] = personal_info['surname']\n",
    "        speech['group'] = personal_info['group']\n",
    "        speech['acronym'] = personal_info['acronym']\n",
    "\n",
    "        with open(out_path, 'w', encoding='utf-8') as out_speech_file:\n",
    "            out_speech_file.write(json_dumps(speech, indent=4, ensure_ascii=False))\n",
    "\n",
    "\n",
    "#parse_speech('dscd-12-019-075.json')\n",
    "speeches_paths = listdir(speeches_folder_path)\n",
    "for speech_path in speeches_paths:\n",
    "    parse_speech(speech_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5.- Obtenir discursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not isdir(speeches_folder_path):\n",
    "    mkdir(speeches_folder_path)\n",
    "\n",
    "text_paths = listdir(texts_folder_path)\n",
    "for text_path in text_paths:\n",
    "    path = f'{texts_folder_path}/{text_path}'\n",
    "    parts = text_path[:-4].split('-')\n",
    "\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        try:\n",
    "            speeches = parse_diary(text, parts[0], int(parts[1]), int(parts[2]))\n",
    "            for speech in speeches:\n",
    "                speech_path = f'{speeches_folder_path}/{text_path[:-4]}-{speech[\"order\"]:03d}.json'\n",
    "                json_speech = json_dumps(speech, indent=4, ensure_ascii=False)\n",
    "                with open(speech_path, 'w', encoding='utf-8') as speech_file:\n",
    "                    speech_file.write(json_speech)\n",
    "        except IndexError:\n",
    "            print('error at parse', text_path)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.1.- Incloure informació personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not isdir(speeches_to_index_folder_path):\n",
    "    makedirs(speeches_to_index_folder_path)\n",
    "\n",
    "df_people = pd.read_csv()\n",
    "\n",
    "def find_personal_info(speech_info):\n",
    "    if 'surname' not in speech_info or speech_info['surname'] is None:\n",
    "        return None\n",
    "\n",
    "    surname = speech_info['surname'].strip().upper()\n",
    "    surname = unidecode(surname).replace(\"-\", \" \")\n",
    "\n",
    "    if surname == 'PRESIDENTE' or surname == 'PRESIDENTA':\n",
    "        if 'presidency' not in speech_info or speech_info['presidency'] is None:\n",
    "            return None\n",
    "\n",
    "        fullname = speech_info['presidency'].strip().upper()\n",
    "        fullname = unidecode(fullname)\n",
    "        found_president = df_people.loc[df_people['unidecode_name'] + ' ' + df_people['unidecode_surname'] == fullname]\n",
    "        if found_president.shape[0] == 0:\n",
    "            return None\n",
    "        return found_president.iloc[0].to_dict()\n",
    "\n",
    "    surname_with_explanatory = [\n",
    "        'SECRETARIO',\n",
    "        'SECRETARIA',\n",
    "        'VICEPRESIDENTA',\n",
    "        'VICEPRESIDENTE',\n",
    "        'PRESIDENTE DEL GOBIERNO EN FUNCIONES',\n",
    "        'PRESIDENTA DEL GOBIERNO EN FUNCIONES',\n",
    "        'DEFENSORA DEL PUEBLO',\n",
    "        'DEFENSOR DEL PUEBLO',\n",
    "        'MINISTRO DEL INTERIOR EN FUNCIONES',\n",
    "        'MINISTRA DEL INTERIOR EN FUNCIONES'\n",
    "    ]\n",
    "    if surname in surname_with_explanatory and 'explanatory' in speech_info:\n",
    "        surname = speech_info['explanatory'].strip().upper()\n",
    "        surname = unidecode(surname).replace(\"-\", \" \")\n",
    "\n",
    "    found = df_people.loc[df_people['unidecode_surname'] == surname]\n",
    "    if found.shape[0] == 0:\n",
    "        surname = re.sub(r\"^DE LOS \", \"\", surname)\n",
    "        surname = re.sub(r\"^DE LAS \", \"\", surname)\n",
    "        surname = re.sub(r\"^DE LA \", \"\", surname)\n",
    "        surname = re.sub(r\"^DEL \", \"\", surname)\n",
    "        surname = re.sub(r\"^DE \", \"\", surname)\n",
    "        found = df_people.loc[df_people['unidecode_surname'] == surname]\n",
    "        if found.shape[0] == 0:\n",
    "            return None\n",
    "    return found.iloc[0].to_dict()\n",
    "\n",
    "\n",
    "def parse_speech(speech_file_name):\n",
    "    raw_path = f'{speeches_folder_path}/{speech_file_name}'\n",
    "    out_path = f'{speeches_to_index_folder_path}/{speech_file_name}'\n",
    "\n",
    "    with open(raw_path, 'r', encoding='utf-8') as raw_speech_file:\n",
    "        speech = json_loads(raw_speech_file.read())\n",
    "        personal_info = find_personal_info(speech)\n",
    "        if personal_info is None:\n",
    "            print(raw_path, speech['surname'] if 'surname' in speech else 'NULL', 'Author not found')\n",
    "            return\n",
    "        speech['name'] = personal_info['name']\n",
    "        speech['surname'] = personal_info['surname']\n",
    "        speech['group'] = personal_info['group']\n",
    "        speech['acronym'] = personal_info['acronym']\n",
    "\n",
    "        with open(out_path, 'w', encoding='utf-8') as out_speech_file:\n",
    "            out_speech_file.write(json_dumps(speech, indent=4, ensure_ascii=False))\n",
    "\n",
    "\n",
    "#parse_speech('dss-14-404-044.json')\n",
    "\n",
    "speeches_paths = listdir(speeches_folder_path)\n",
    "for speech_path in speeches_paths:\n",
    "    parse_speech(speech_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "750e7f6c7e31e9d90d6d316f858439754a47ca3756af184519d8b3f179eed3b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
