{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from downloadDiaryOfSessions.main import download\n",
    "from rabbitmqSender.main import RabbitSender\n",
    "from diaryParser.main import  parse_diary\n",
    "\n",
    "import json\n",
    "from os.path import isdir, isfile\n",
    "from bs4 import BeautifulSoup\n",
    "from os import listdir, makedirs, mkdir\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "\n",
    "legislatures = [11, 12, 13, 14]\n",
    "max_errors = 50\n",
    "data_folder = './.data/'\n",
    "dscd_path = f'{data_folder}diary_session_congress_deputies_pdfs'\n",
    "dss_path = f'{data_folder}diary_session_senate_pdfs'\n",
    "texts_folder_path = f'{data_folder}texts'\n",
    "speeches_folder_path = f'{data_folder}speeches'\n",
    "open_data_senators_xml = 'https://www.senado.es/web/ficopendataservlet?tipoFich=10#'\n",
    "open_data_groups_xml = 'https://www.senado.es/web/ficopendataservlet?tipoFich=4&legis=13#'\n",
    "senators_xml_path = './.data/opendata_senators.xml'\n",
    "groups_xml_path = './.data/opendata_group.xml'\n",
    "senate_pkl_path = './.data/senators.pkl'\n",
    "deputies_pkl_path = './.data/deputies.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.- Descarregar diaris de sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def diary_session_congress_deputies_url(legislature, plenary):\n",
    "    return f\"https://www.congreso.es/public_oficiales/L{legislature}/CONG/DS/PL/DSCD-{legislature}-PL-{plenary}.PDF\"\n",
    "\n",
    "\n",
    "def diary_session_senate_url(legislature, plenary):\n",
    "    return f\"https://www.senado.es/legis{legislature}/publicaciones/pdf/senado/ds/DS_C_{legislature}_{plenary}.PDF\"\n",
    "\n",
    "\n",
    "def download_diary_session(local_path, prefix, diary_session_url):\n",
    "    if not isdir(local_path):\n",
    "        makedirs(local_path)\n",
    "\n",
    "    for current_legislature in legislatures:\n",
    "        current_plenary = 1\n",
    "        consecutive_errors = 0\n",
    "        while consecutive_errors < max_errors:\n",
    "            url = diary_session_url(current_legislature, current_plenary)\n",
    "            file = f\"{prefix}-{current_legislature}-{current_plenary:03d}\"\n",
    "            if download(url, local_path, file):\n",
    "                consecutive_errors = 0\n",
    "            else:\n",
    "                consecutive_errors += 1\n",
    "\n",
    "            current_plenary += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1.- Diaris de sessions del congress de diputats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "download_diary_session(dscd_path, 'dscd', diary_session_congress_deputies_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2.- Diaris de sessions del senat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "download_diary_session(dss_path, 'dss', diary_session_senate_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.- Convertir pagines de pdf a imatges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`docker-compose -f docker-compose-pdf-to-img.yml -p tfg-pdf-to-img up -d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sender = RabbitSender('localhost', 5672, 'myuser', 'mypassword', 'pdf-to-img')\n",
    "\n",
    "for file in listdir(dscd_path):\n",
    "    sender.send(f'{dscd_path}/{file}'[len(data_folder):])\n",
    "\n",
    "for file in listdir(dss_path):\n",
    "    sender.send(f'{dss_path}/{file}'[len(data_folder):])\n",
    "\n",
    "sender.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[RabbitMQ queues management](http://localhost:15672/#/queues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.- Convertir imatges a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`docker-compose -f docker-compose-img-to-txt.yml -p tfg-img-to-txt up -d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sender = RabbitSender('localhost', 5672, 'myuser', 'mypassword', 'img-to-txt')\n",
    "\n",
    "for file in listdir(f'{data_folder}images'):\n",
    "    sender.send(file)\n",
    "\n",
    "sender.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.- Obtenir diputats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_deputies(legislature):\n",
    "    url_deputies = \"https://www.congreso.es/busqueda-de-diputados?p_p_id=diputadomodule&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_resource_id=searchDiputados&p_p_cacheability=cacheLevelPage\"\n",
    "\n",
    "    payload={'_diputadomodule_idLegislatura': legislature,\n",
    "             '_diputadomodule_genero': '0',\n",
    "             '_diputadomodule_grupo': 'all',\n",
    "             '_diputadomodule_tipo': '2',\n",
    "             '_diputadomodule_nombre': '',\n",
    "             '_diputadomodule_apellidos': '',\n",
    "             '_diputadomodule_formacion': 'all',\n",
    "             '_diputadomodule_filtroProvincias': '[]',\n",
    "             '_diputadomodule_nombreCircunscripcion': ''}\n",
    "\n",
    "    response = requests.request(\"POST\", url_deputies, data=payload)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_deputies = None\n",
    "for current_legislature in legislatures:\n",
    "    data = get_deputies(current_legislature)\n",
    "    data_json = json.loads(data)\n",
    "    if df_deputies is None:\n",
    "        df_deputies = json_normalize(data_json['data'])\n",
    "    else:\n",
    "        new_df = json_normalize(data_json['data'])\n",
    "        for index, row in new_df.iterrows():\n",
    "            current_row_df = df_deputies[(df_deputies.apellidosNombre == row['apellidosNombre']) & (df_deputies.formacion == row['formacion'])]\n",
    "            if current_row_df.empty:\n",
    "                df_deputies = pd.concat([df_deputies, row])\n",
    "            else:\n",
    "                df_deputies.loc[(df_deputies.apellidosNombre == row['apellidosNombre']) & (df_deputies.formacion == row['formacion']), 'fchBaja'] = row['fchBaja']\n",
    "                df_deputies.loc[(df_deputies.apellidosNombre == row['apellidosNombre']) & (df_deputies.formacion == row['formacion']), 'idLegislatura'] = f'{current_row_df.iloc[0].idLegislatura},{row[\"idLegislatura\"]}'\n",
    "\n",
    "df_deputies['apellidos'] = df_deputies['apellidos'].str.strip()\n",
    "df_deputies.to_pickle(deputies_pkl_path)\n",
    "df_deputies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5.- Obtenir senadors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "senators_response = requests.get(open_data_senators_xml)\n",
    "with open(senators_xml_path, 'w', encoding='utf-8') as senators_file:\n",
    "    senators_file.write(senators_response.text)\n",
    "\n",
    "groups_response = requests.get(open_data_groups_xml)\n",
    "groups_data = BeautifulSoup(groups_response.text, 'xml')\n",
    "data_headers = groups_data.findAll('datosCabecera')\n",
    "\n",
    "groups = []\n",
    "for header in data_headers:\n",
    "    groups.append({\n",
    "        'code': header.find('codigo').text,\n",
    "        'fullname': header.find('nombre').text,\n",
    "        'acronym': header.find('siglas').text\n",
    "    })\n",
    "\n",
    "with open(groups_xml_path, 'w', encoding='utf-8') as groups_file:\n",
    "    groups_file.write(groups_response.text)\n",
    "\n",
    "df_senators = pd.read_xml(senators_xml_path)\n",
    "df_senators = df_senators[df_senators['legislatura'].isin(legislatures)]\n",
    "\n",
    "df_groups = pd.DataFrame(groups)\n",
    "\n",
    "df_senate = pd.merge(df_senators, df_groups, how='left', left_on=['grupoSiglas'], right_on=['code'])\n",
    "df_senate.to_pickle(senate_pkl_path)\n",
    "df_senate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6.- Obtenir discursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not isdir(speeches_folder_path):\n",
    "    mkdir(speeches_folder_path)\n",
    "\n",
    "text_paths = listdir(texts_folder_path)\n",
    "for text_path in text_paths:\n",
    "    path = f'{texts_folder_path}/{text_path}'\n",
    "    parts = text_path[:-4].split('-')\n",
    "\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        try:\n",
    "            speeches = parse_diary(text, parts[0], int(parts[1]), int(parts[2]))\n",
    "            for speech in speeches:\n",
    "                speech_path = f'{speeches_folder_path}/{text_path[:-4]}-{speech[\"order\"]:03d}.json'\n",
    "                json_speech = json.dumps(speech, indent=4, ensure_ascii=False)\n",
    "                with open(speech_path, 'w', encoding='utf-8') as speech_file:\n",
    "                    speech_file.write(json_speech)\n",
    "        except IndexError:\n",
    "            print('error at parse', text_path)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 6.1.- Incloure informaciÃ³ personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_senators = pd.read_pickle(senate_pkl_path)\n",
    "df_senators['apellidos_unidecode'] = df_senators['apellidos'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_deputies = pd.read_pickle(deputies_pkl_path)\n",
    "df_deputies['apellidos_unidecode'] = df_deputies['apellidos'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "\n",
    "def find_personal_info(speech_info, df):\n",
    "    if 'surname' not in speech_info:\n",
    "        return None\n",
    "    surname = speech_info['surname'].strip()\n",
    "\n",
    "    if surname == 'PRESIDENTE' or surname == 'PRESIDENTA':\n",
    "        fullname = speech_info['presidency'].strip()\n",
    "        found_president = df.loc[df['nombre'].str.upper() + ' ' + df['apellidos'].str.upper() == fullname.upper()]\n",
    "        if found_president.shape[0] == 0:\n",
    "            return None\n",
    "        return found_president.iloc[0].to_dict()\n",
    "    surname_with_explanatory = [\n",
    "        'SECRETARIO',\n",
    "        'SECRETARIA',\n",
    "        'VICEPRESIDENTA',\n",
    "        'VICEPRESIDENTE',\n",
    "        'PRESIDENTE DEL GOBIERNO EN FUNCIONES',\n",
    "        'PRESIDENTA DEL GOBIERNO EN FUNCIONES',\n",
    "        'DEFENSORA DEL PUEBLO',\n",
    "        'DEFENSOR DEL PUEBLO',\n",
    "        'MINISTRO DEL INTERIOR EN FUNCIONES',\n",
    "        'MINISTRA DEL INTERIOR EN FUNCIONES'\n",
    "    ]\n",
    "    if surname in surname_with_explanatory and 'explanatory' in speech_info:\n",
    "        surname = speech_info['explanatory'].strip()\n",
    "\n",
    "    found = df.loc[df['apellidos'].str.upper() == surname.upper()]\n",
    "    if found.shape[0] == 0:\n",
    "        surname_unidecode = unidecode(surname.upper())\n",
    "        found = df.loc[df['apellidos_unidecode'].str.upper() == surname_unidecode]\n",
    "        if found.shape[0] == 0:\n",
    "            return None\n",
    "    return found.iloc[0].to_dict()\n",
    "\n",
    "\n",
    "def parse_dscd(speech_file_path):\n",
    "    path = f'{speeches_folder_path}/{speech_file_path}'\n",
    "    with open(path, 'r', encoding='utf8') as file:\n",
    "        speech = json.loads(file.read())\n",
    "        personal_info = find_personal_info(speech, df_deputies)\n",
    "        if personal_info is not None:\n",
    "            speech['name'] = personal_info['nombre']\n",
    "            speech['surname'] = personal_info['apellidos']\n",
    "            speech['group'] = personal_info['grupo']\n",
    "            speech['acronym'] = personal_info['formacion']\n",
    "            speech['gender'] = 'male' if personal_info['genero'] == 1 else 'female'\n",
    "\n",
    "            json_speech = json.dumps(speech, indent=4, ensure_ascii=False)\n",
    "            with open(path, 'w', encoding='utf-8') as speech_file:\n",
    "                speech_file.write(json_speech)\n",
    "        else:\n",
    "            print(path, speech['surname'], 'Author not found')\n",
    "\n",
    "\n",
    "def parse_dss(speech_file_path):\n",
    "    path = f'{speeches_folder_path}/{speech_file_path}'\n",
    "    with open(path, 'r', encoding='utf8') as file:\n",
    "        speech = json.loads(file.read())\n",
    "        personal_info = find_personal_info(speech, df_senators)\n",
    "        if personal_info is not None:\n",
    "            print(personal_info)\n",
    "            speech['name'] = personal_info['nombre']\n",
    "            speech['surname'] = personal_info['apellidos']\n",
    "            speech['group'] = personal_info['fullname']\n",
    "            speech['acronym'] = personal_info['acronym']\n",
    "\n",
    "            json_speech = json.dumps(speech, indent=4, ensure_ascii=False)\n",
    "            with open(path, 'w', encoding='utf-8') as speech_file:\n",
    "                speech_file.write(json_speech)\n",
    "        else:\n",
    "            print(path, speech['surname'], 'Author not found')\n",
    "\n",
    "\n",
    "speeches_paths = listdir(speeches_folder_path)\n",
    "for speech_path in speeches_paths:\n",
    "    if speech_path.startswith('dss'):\n",
    "        parse_dss(speech_path)\n",
    "    else:\n",
    "        parse_dscd(speech_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "750e7f6c7e31e9d90d6d316f858439754a47ca3756af184519d8b3f179eed3b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
