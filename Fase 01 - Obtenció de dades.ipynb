{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from downloadDiaryOfSessions.main import download\n",
    "from rabbitmqSender.main import RabbitSender\n",
    "from diaryParser.main import  parse_diary\n",
    "\n",
    "from json import loads as json_loads, dumps as json_dumps\n",
    "from os.path import isdir\n",
    "from bs4 import BeautifulSoup\n",
    "from os import listdir, makedirs, mkdir\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "\n",
    "legislatures = [11, 12, 13, 14]\n",
    "max_errors = 50\n",
    "data_folder = './.data/'\n",
    "dscd_path = f'{data_folder}diary_session_congress_deputies_pdfs'\n",
    "dss_path = f'{data_folder}diary_session_senate_pdfs'\n",
    "texts_folder_path = f'{data_folder}texts'\n",
    "speeches_folder_path = f'{data_folder}speeches'\n",
    "speeches_to_index_folder_path = f'{data_folder}speeches_to_index'\n",
    "open_data_senators_xml = 'https://www.senado.es/web/ficopendataservlet?tipoFich=10#'\n",
    "open_data_groups_xml = 'https://www.senado.es/web/ficopendataservlet?tipoFich=4&legis=13#'\n",
    "senators_xml_path = f'{data_folder}opendata_senators.xml'\n",
    "groups_xml_path = f'{data_folder}opendata_group.xml'\n",
    "people_senate_csv_path = f'{data_folder}people_senate.csv'\n",
    "people_congress_csv_path = f'{data_folder}people_congress.csv'\n",
    "people_csv_path = f'{data_folder}people.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.- Descarregar diaris de sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def diary_session_congress_deputies_url(legislature, plenary):\n",
    "    return f\"https://www.congreso.es/public_oficiales/L{legislature}/CONG/DS/PL/DSCD-{legislature}-PL-{plenary}.PDF\"\n",
    "\n",
    "\n",
    "def diary_session_senate_url(legislature, plenary):\n",
    "    return f\"https://www.senado.es/legis{legislature}/publicaciones/pdf/senado/ds/DS_C_{legislature}_{plenary}.PDF\"\n",
    "\n",
    "\n",
    "def download_diary_session(local_path, prefix, diary_session_url):\n",
    "    if not isdir(local_path):\n",
    "        makedirs(local_path)\n",
    "\n",
    "    for current_legislature in legislatures:\n",
    "        current_plenary = 1\n",
    "        consecutive_errors = 0\n",
    "        while consecutive_errors < max_errors:\n",
    "            url = diary_session_url(current_legislature, current_plenary)\n",
    "            file = f\"{prefix}-{current_legislature}-{current_plenary:03d}\"\n",
    "            if download(url, local_path, file):\n",
    "                consecutive_errors = 0\n",
    "            else:\n",
    "                consecutive_errors += 1\n",
    "\n",
    "            current_plenary += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1.- Diaris de sessions del congress de diputats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "download_diary_session(dscd_path, 'dscd', diary_session_congress_deputies_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2.- Diaris de sessions del senat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "download_diary_session(dss_path, 'dss', diary_session_senate_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.- Convertir pagines de pdf a imatges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`docker-compose -f docker-compose-pdf-to-img.yml -p tfg-pdf-to-img up -d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sender = RabbitSender('localhost', 5672, 'myuser', 'mypassword', 'pdf-to-img')\n",
    "\n",
    "for file in listdir(dscd_path):\n",
    "    sender.send(f'{dscd_path}/{file}'[len(data_folder):])\n",
    "\n",
    "for file in listdir(dss_path):\n",
    "    sender.send(f'{dss_path}/{file}'[len(data_folder):])\n",
    "\n",
    "sender.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[RabbitMQ queues management](http://localhost:15672/#/queues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.- Convertir imatges a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`docker-compose -f docker-compose-img-to-txt.yml -p tfg-img-to-txt up -d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sender = RabbitSender('localhost', 5672, 'myuser', 'mypassword', 'img-to-txt')\n",
    "\n",
    "for file in listdir(f'{data_folder}images'):\n",
    "    sender.send(file)\n",
    "\n",
    "sender.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.- Obtenir diputats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_deputies(legislature):\n",
    "    url_deputies = \"https://www.congreso.es/busqueda-de-diputados?p_p_id=diputadomodule&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_resource_id=searchDiputados&p_p_cacheability=cacheLevelPage\"\n",
    "\n",
    "    payload={'_diputadomodule_idLegislatura': legislature,\n",
    "             '_diputadomodule_genero': '0',\n",
    "             '_diputadomodule_grupo': 'all',\n",
    "             '_diputadomodule_tipo': '2',\n",
    "             '_diputadomodule_nombre': '',\n",
    "             '_diputadomodule_apellidos': '',\n",
    "             '_diputadomodule_formacion': 'all',\n",
    "             '_diputadomodule_filtroProvincias': '[]',\n",
    "             '_diputadomodule_nombreCircunscripcion': ''}\n",
    "\n",
    "    response = requests.request(\"POST\", url_deputies, data=payload)\n",
    "    return response.text\n",
    "\n",
    "df_deputies = None\n",
    "for current_legislature in legislatures:\n",
    "    json = get_deputies(11)\n",
    "    data = json_loads(json)\n",
    "    df = json_normalize(data['data'])\n",
    "    df_deputies = df if df_deputies is None else pd.concat([df_deputies, df])\n",
    "\n",
    "df_deputies = df_deputies.sort_values('apellidos').drop_duplicates(subset=['nombre', 'genero', 'grupo', 'formacion'])\n",
    "df_deputies.to_csv(people_congress_csv_path, index=False)\n",
    "df_deputies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5.- Obtenir senadors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "senators_response = requests.get(open_data_senators_xml)\n",
    "with open(senators_xml_path, 'w', encoding='utf-8') as senators_file:\n",
    "    senators_file.write(senators_response.text)\n",
    "\n",
    "groups_response = requests.get(open_data_groups_xml)\n",
    "groups_data = BeautifulSoup(groups_response.text, 'xml')\n",
    "data_headers = groups_data.findAll('datosCabecera')\n",
    "\n",
    "groups = []\n",
    "for header in data_headers:\n",
    "    groups.append({\n",
    "        'code': header.find('codigo').text,\n",
    "        'fullname': header.find('nombre').text,\n",
    "        'acronym': header.find('siglas').text\n",
    "    })\n",
    "\n",
    "with open(groups_xml_path, 'w', encoding='utf-8') as groups_file:\n",
    "    groups_file.write(groups_response.text)\n",
    "\n",
    "df_senators = pd.read_xml(senators_xml_path)\n",
    "df_senators = df_senators[df_senators['legislatura'].isin(legislatures)]\n",
    "\n",
    "df_groups = pd.DataFrame(groups)\n",
    "\n",
    "df_senate = pd.merge(df_senators, df_groups, how='left', left_on=['grupoSiglas'], right_on=['code'])\n",
    "df_senate.to_csv(people_senate_csv_path, index=False)\n",
    "df_senate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6.- Obtenir discursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not isdir(speeches_folder_path):\n",
    "    mkdir(speeches_folder_path)\n",
    "\n",
    "text_paths = listdir(texts_folder_path)\n",
    "for text_path in text_paths:\n",
    "    path = f'{texts_folder_path}/{text_path}'\n",
    "    parts = text_path[:-4].split('-')\n",
    "\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        try:\n",
    "            speeches = parse_diary(text, parts[0], int(parts[1]), int(parts[2]))\n",
    "            for speech in speeches:\n",
    "                speech_path = f'{speeches_folder_path}/{text_path[:-4]}-{speech[\"order\"]:03d}.json'\n",
    "                json_speech = json_dumps(speech, indent=4, ensure_ascii=False)\n",
    "                with open(speech_path, 'w', encoding='utf-8') as speech_file:\n",
    "                    speech_file.write(json_speech)\n",
    "        except IndexError:\n",
    "            print('error at parse', text_path)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 6.1.- Incloure informació personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#https://www.lamoncloa.gob.es/gobierno/gobiernosporlegislaturas/Paginas/xiv_legislatura.aspx\n",
    "\n",
    "df_senators = pd.read_csv(people_senate_csv_path)\n",
    "df_senators['unidecode_name'] = df_senators['nombre'].str.replace(\"-\", \" \").str.upper().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_senators['unidecode_surname'] = df_senators['apellidos'].str.replace(\"-\", \" \").str.upper().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "df_deputies = pd.read_csv(people_congress_csv_path)\n",
    "df_deputies['unidecode_name'] = df_deputies['nombre'].str.replace(\"-\", \" \").str.upper().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_deputies['unidecode_surname'] = df_deputies['apellidos'].str.replace(\"-\", \" \").str.upper().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "\n",
    "df_deputies['name'] = df_deputies['nombre'].str.upper()\n",
    "df_deputies['surname'] = df_deputies['apellidos'].str.upper()\n",
    "df_deputies['group'] = df_deputies['grupo'].str.upper()\n",
    "df_deputies['acronym'] = df_deputies['formacion'].str.upper()\n",
    "\n",
    "df_senators['name'] = df_senators['nombre'].str.upper()\n",
    "df_senators['surname'] = df_senators['apellidos'].str.upper()\n",
    "df_senators['group'] = df_senators['fullname'].str.upper()\n",
    "df_senators['acronym'] = df_senators['acronym'].str.upper()\n",
    "\n",
    "df_people = pd.concat([\n",
    "    df_deputies[['name', 'unidecode_name', 'surname', 'unidecode_surname', 'group', 'acronym']],\n",
    "    df_senators[['name', 'unidecode_name', 'surname', 'unidecode_surname', 'group', 'acronym']]],\n",
    "    ignore_index=True)\n",
    "\n",
    "df_people.to_csv(people_csv_path, index=False)\n",
    "\n",
    "df_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not isdir(speeches_to_index_folder_path):\n",
    "    makedirs(speeches_to_index_folder_path)\n",
    "\n",
    "df_people = pd.read_csv()\n",
    "\n",
    "def find_personal_info(speech_info):\n",
    "    if 'surname' not in speech_info or speech_info['surname'] is None:\n",
    "        return None\n",
    "\n",
    "    surname = speech_info['surname'].strip().upper()\n",
    "    surname = unidecode(surname).replace(\"-\", \" \")\n",
    "\n",
    "    if surname == 'PRESIDENTE' or surname == 'PRESIDENTA':\n",
    "        if 'presidency' not in speech_info or speech_info['presidency'] is None:\n",
    "            return None\n",
    "\n",
    "        fullname = speech_info['presidency'].strip().upper()\n",
    "        fullname = unidecode(fullname)\n",
    "        found_president = df_people.loc[df_people['unidecode_name'] + ' ' + df_people['unidecode_surname'] == fullname]\n",
    "        if found_president.shape[0] == 0:\n",
    "            return None\n",
    "        return found_president.iloc[0].to_dict()\n",
    "\n",
    "    surname_with_explanatory = [\n",
    "        'SECRETARIO',\n",
    "        'SECRETARIA',\n",
    "        'VICEPRESIDENTA',\n",
    "        'VICEPRESIDENTE',\n",
    "        'PRESIDENTE DEL GOBIERNO EN FUNCIONES',\n",
    "        'PRESIDENTA DEL GOBIERNO EN FUNCIONES',\n",
    "        'DEFENSORA DEL PUEBLO',\n",
    "        'DEFENSOR DEL PUEBLO',\n",
    "        'MINISTRO DEL INTERIOR EN FUNCIONES',\n",
    "        'MINISTRA DEL INTERIOR EN FUNCIONES'\n",
    "    ]\n",
    "    if surname in surname_with_explanatory and 'explanatory' in speech_info:\n",
    "        surname = speech_info['explanatory'].strip().upper()\n",
    "        surname = unidecode(surname).replace(\"-\", \" \")\n",
    "\n",
    "    found = df_people.loc[df_people['unidecode_surname'] == surname]\n",
    "    if found.shape[0] == 0:\n",
    "        surname = re.sub(r\"^DE LOS \", \"\", surname)\n",
    "        surname = re.sub(r\"^DE LAS \", \"\", surname)\n",
    "        surname = re.sub(r\"^DE LA \", \"\", surname)\n",
    "        surname = re.sub(r\"^DEL \", \"\", surname)\n",
    "        surname = re.sub(r\"^DE \", \"\", surname)\n",
    "        found = df_people.loc[df_people['unidecode_surname'] == surname]\n",
    "        if found.shape[0] == 0:\n",
    "            return None\n",
    "    return found.iloc[0].to_dict()\n",
    "\n",
    "\n",
    "def parse_speech(speech_file_name):\n",
    "    raw_path = f'{speeches_folder_path}/{speech_file_name}'\n",
    "    out_path = f'{speeches_to_index_folder_path}/{speech_file_name}'\n",
    "\n",
    "    with open(raw_path, 'r', encoding='utf-8') as raw_speech_file:\n",
    "        speech = json_loads(raw_speech_file.read())\n",
    "        personal_info = find_personal_info(speech)\n",
    "        if personal_info is None:\n",
    "            print(raw_path, speech['surname'] if 'surname' in speech else 'NULL', 'Author not found')\n",
    "            return\n",
    "        speech['name'] = personal_info['name']\n",
    "        speech['surname'] = personal_info['surname']\n",
    "        speech['group'] = personal_info['group']\n",
    "        speech['acronym'] = personal_info['acronym']\n",
    "\n",
    "        with open(out_path, 'w', encoding='utf-8') as out_speech_file:\n",
    "            out_speech_file.write(json_dumps(speech, indent=4, ensure_ascii=False))\n",
    "\n",
    "\n",
    "#parse_speech('dss-14-404-044.json')\n",
    "\n",
    "speeches_paths = listdir(speeches_folder_path)\n",
    "for speech_path in speeches_paths:\n",
    "    parse_speech(speech_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "750e7f6c7e31e9d90d6d316f858439754a47ca3756af184519d8b3f179eed3b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
